
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>  03. Reinforcement Learning |    Rongyan's Blog</title>
<meta content="Financial Engineering | Mathematics | Computer Science" name="description"/>
<!-- 标签页图标 -->
<!-- 图标库 -->
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet"/>
<!-- 动画库 -->
<link href="https://cdn.jsdelivr.net/gh/fushaolei/cdn-white@1.0/css/animate.css" rel="stylesheet">
<!-- css文件 -->
<link href="/css/white.css" rel="stylesheet"/>
<!-- 代码高亮 -->
<meta content="Hexo 6.2.0" name="generator"/></link></head>
<body>
<div class="menu-outer">
<div class="menu-inner">
<div class="menu-site-name animate__animated animate__fadeInUp">
<a href="/">
          Rongyan's Blog
        </a>
<div class="menu-redirect"><a class="nav-link back-topic-link" href="/categories/ai/ai-fundamentals/">← AI Fundamentals</a></div></div>
<div class="menu-group">
<ul class="menu-ul">
<a class="nav-link" href="/">
<li class="menu-li animate__animated animate__fadeInUp">
              HOME
            </li>
</a>
<a class="nav-link" href="/archives">
<li class="menu-li animate__animated animate__fadeInUp">
              BLOG
            </li>
</a>
<li class="menu-li animate__animated animate__fadeInUp" id="sort">
             CATEGORIES
             <div class="categories-outer" id="sort-div">
<ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AboutMe/">AboutMe</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ai/">AI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs/">CS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/quant/">Quant</a></li></ul>
</div>
</li>
<a href="/search">
<li class="menu-li animate__animated animate__fadeInUp">
<i class="ri-search-line"></i>
</li>
</a>
<li class="menu-li animate__animated animate__fadeInUp lang-switcher-desktop">
<a href="/2026/02/07/Reinforcement-Learning/index.html">EN</a> |
            <a href="/2026/02/07/Reinforcement-Learning/index-zh.html">中文</a>
</li>
<li class="menu-li animate__animated animate__fadeInUp" id="mobile-menu">
<i class="ri-menu-line"></i>
</li>
</ul>
</div>
</div>
</div>
<div class="animate__animated animate__fadeIn" id="mobile-main">
<div class="mobile-menu-inner">
<div class="mobile-menu-site-name animate__animated animate__fadeInUp">
<a href="/">
        Rongyan's Blog
      </a>
</div>
<div class="mobile-menu-group" id="mobile-close">
<i class="ri-close-line"></i>
</div>
</div>
<div class="mobile-menu-div">
<a class="mobile-nav-link" href="/">
<div class="mobile-menu-child animate__animated animate__fadeInUp">
<span>HOME</span>
</div>
</a>
<a class="mobile-nav-link" href="/archives">
<div class="mobile-menu-child animate__animated animate__fadeInUp">
<span>BLOG</span>
</div>
</a>
<div class="mobile-menu-child animate__animated animate__fadeInUp lang-switcher-mobile">
<a href="/2026/02/07/Reinforcement-Learning/index.html">EN</a> |
      <a href="/2026/02/07/Reinforcement-Learning/index-zh.html">中文</a>
</div>
<a href="/search">
<div class="mobile-menu-child animate__animated animate__fadeInUp">
<i class="ri-search-line"></i>
</div>
</a>
</div>
</div>
<div class="body-outer">
<div class="body-inner">
<article class="post-inner">
<div class="post-content-outer">
<div class="post-intro">
<div class="post-title animate__animated animate__fadeInUp">03. Reinforcement Learning</div>
<div class="meta-intro animate__animated animate__fadeInUp">Feb 07 2026</div>
</div>
<div class="post-content-inner">
<div class="post-content-inner-space">
</div>
<div class="post-content-main animate__animated animate__fadeInUp">
<!-- top型目录 -->
<h1 id="RL"><a class="headerlink" href="#RL" title="03. Reinforcement Learning"></a>03. Reinforcement Learning</h1>
<p>Reinforcement learning enables models to improve decision-making by continuously learning from trial and feedback in real or simulated environments, allowing systems to automatically optimize strategies for complex business tasks such as personalized recommendations and operational decision optimization.</p>
<h2 id="What-Is-RL"><a class="headerlink" href="#What-Is-RL" title="What Reinforcement Learning Is"></a>1. What reinforcement learning is</h2>
<p>Reinforcement learning (RL) studies how an agent learns a <strong>policy</strong> to interact with an environment in order to maximize long‑term reward:</p>
<p>\[\max_\pi \; \mathbb{E}_\pi \left[ \sum_{t=0}^{\infty} \gamma^t r_t \right]\]</p>
<p>where \(\gamma \in (0,1)\) is the discount factor.</p>
<h2 id="Loop"><a class="headerlink" href="#Loop" title="The Basic Interaction Loop"></a>2. The basic interaction loop</h2>
<p>At each time step:</p>
<p>\[s_t \rightarrow a_t \rightarrow r_t \rightarrow s_{t+1}\]</p>
<p>with actions sampled from the policy:</p>
<p>\[a_t \sim \pi(a \mid s_t)\]</p>
<h2 id="Core"><a class="headerlink" href="#Core" title="Core Components"></a>3. Core components</h2>
<ul>
<li><strong>State \(s\):</strong> observation of the environment</li>
<li><strong>Action \(a\):</strong> action taken by the agent</li>
<li><strong>Policy \(\pi(a \mid s)\):</strong> probability distribution over actions</li>
<li><strong>Reward \(r\):</strong> scalar feedback</li>
<li><strong>Value function:</strong> \(V^\pi(s) = \mathbb{E}_\pi \left[ \sum_{t=0}^{\infty} \gamma^t r_t \mid s_0 = s \right]\)</li>
<li><strong>Action‑value function:</strong> \(Q^\pi(s,a) = \mathbb{E}_\pi \left[ \sum_{t=0}^{\infty} \gamma^t r_t \mid s_0 = s, a_0 = a \right]\)</li>
</ul>
<h2 id="Challenges"><a class="headerlink" href="#Challenges" title="Why RL Is Challenging"></a>4. Why reinforcement learning is challenging</h2>
<ul>
<li><strong>Delayed rewards:</strong> credit assignment over long horizons</li>
<li><strong>Exploration vs exploitation:</strong> balancing \(\max_a Q(s,a)\) vs. exploration</li>
<li><strong>Non‑stationary data:</strong> policy‑dependent state distribution</li>
</ul>
<h2 id="Categories"><a class="headerlink" href="#Categories" title="Main Categories"></a>5. Main categories of reinforcement learning</h2>
<ul>
<li><strong>Value‑based methods:</strong> \[Q(s,a) \leftarrow Q(s,a) + \alpha \bigl[ r + \gamma \max_{a'} Q(s',a') - Q(s,a) \bigr]\]</li>
<li><strong>Policy‑based methods (REINFORCE):</strong> \[\nabla_\theta J(\theta) = \mathbb{E}\left[ \nabla_\theta \log \pi_\theta(a \mid s) \, R \right]\]</li>
<li><strong>Actor–Critic methods:</strong> \[\nabla_\theta J(\theta) = \mathbb{E}\left[ \nabla_\theta \log \pi_\theta(a \mid s) \, A(s,a) \right]\]</li>
</ul>
<h2 id="Policy-Gradients"><a class="headerlink" href="#Policy-Gradients" title="Intuition Behind Policy Gradients"></a>6. Intuition behind policy gradients</h2>
<p>Policy gradients increase the likelihood of actions proportional to their <strong>advantage</strong>:</p>
<p>\[A(s,a) = Q(s,a) - V(s)\]</p>
<p>so actions better than expected are reinforced.</p>
<h2 id="Applications"><a class="headerlink" href="#Applications" title="Practical Applications"></a>7. Practical applications</h2>
<ul>
<li>Robotics and continuous control</li>
<li>Game playing and planning</li>
<li>Traffic signal optimization</li>
<li>Resource allocation</li>
<li>Recommendation systems (limited RL usage)</li>
</ul>
<h2 id="Deep-Learning"><a class="headerlink" href="#Deep-Learning" title="Relationship with Deep Learning"></a>8. Relationship with deep learning</h2>
<p>Deep neural networks approximate policies or value functions:</p>
<p>\[\pi_\theta(a \mid s), \quad V_\phi(s), \quad Q_\psi(s,a)\]</p>
<p>allowing RL to scale to high‑dimensional state spaces.</p>
<h2 id="Takeaway"><a class="headerlink" href="#Takeaway" title="Key Takeaway"></a>9. Key takeaway</h2>
<p>Reinforcement learning optimizes decision‑making by maximizing expected cumulative reward:</p>
<p>\[\pi^* = \arg\max_\pi \mathbb{E}_\pi \left[ \sum_{t=0}^{\infty} \gamma^t r_t \right]\]</p>
<!-- 分类文章 -->
<div class="post-categoris-bottom">
<div class="post-categoris-name">AI</div>
<ul>
<li class="me base">
<a class="post-categoris-bottom-link" href="/2026/02/08/Multimodal/">04. Multimodal and Cross-Modal Fusion</a>
</li>
</ul>
</div>
</div><div class="post-content-inner-space">
<div class="space-toc-main animate__animated animate__fadeInUp">
<ol class="space-toc"><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#What-Is-RL"><span class="space-toc-text">1. What reinforcement learning is</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Loop"><span class="space-toc-text">2. The basic interaction loop</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Core"><span class="space-toc-text">3. Core components</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Challenges"><span class="space-toc-text">4. Why reinforcement learning is challenging</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Categories"><span class="space-toc-text">5. Main categories of reinforcement learning</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Policy-Gradients"><span class="space-toc-text">6. Intuition behind policy gradients</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Applications"><span class="space-toc-text">7. Practical applications</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Deep-Learning"><span class="space-toc-text">8. Relationship with deep learning</span></a></li><li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Takeaway"><span class="space-toc-text">9. Key takeaway</span></a></li></ol>
</div>
</div>
</div>
<!-- 评论 -->
</div>
</article>
</div>
</div>
<!-- 如果是home模式的话，不在首页就显示footer，如果不是home模式的话 所有都显示footer -->
<div class="footer-outer animate__animated animate__fadeInUp">
<div class="footer-inner">
<div class="footer-text">
<p>Artificial Intelligence |  Financial Engineering | Mathematics | Computer Science  <strong>Rongyan <i class="ri-copyright-line"></i> 2026</strong></p>
</div>
<div class="footer-contact">
<ul class="footer-ul">
<li class="footer-li">
<a href="https://github.com/RongyanYuan" target="_blank">
<i class="ri-github-line"></i>
</a>
</li>
<li class="footer-li">
<a href="mailto:adrianrongyanyun@gmail.com" target="_blank">
<i class="ri-mail-line"></i>
</a>
</li>
<li class="footer-li">
<a href="https://www.linkedin.com/in/rongyan-yuan-a076971b2/" target="_blank">
<i class="ri-linkedin-box-line"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
<script src="/js/white.js"></script>
<script>
  window.MathJax = {
    tex: {inlineMath: [['\\(','\\)'], ['$', '$']]},
    svg: {fontCache: 'global'}
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</body>
</html>
