<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>  02. Convolutional Neural Networks |    Rongyan&#39;s Blog</title>
  <meta name="description" content="Financial Engineering | Mathematics | Computer Science">
  <link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fushaolei/cdn-white@1.0/css/animate.css"/>
  <link rel="stylesheet" href="/css/white.css">
</head>
<body>

<div class="menu-outer">
  <div class="menu-inner">
    <div class="menu-site-name  animate__animated  animate__fadeInUp">
      <a href="/">Rongyan&#39;s Blog</a>
    </div>
    <div class="menu-group">
      <ul class="menu-ul">
        <a href="/" class="nav-link"><li class="menu-li  animate__animated  animate__fadeInUp">HOME</li></a>
        <a href="/archives" class="nav-link"><li class="menu-li  animate__animated  animate__fadeInUp">BLOG</li></a>
        <li class="menu-li animate__animated  animate__fadeInUp" id="sort">
           CATEGORIES
           <div class="categories-outer " id="sort-div">
             <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AboutMe/">AboutMe</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ai/">AI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs/">CS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/quant/">Quant</a></li></ul>
           </div>
        </li>
        <a href="/search"><li class="menu-li  animate__animated  animate__fadeInUp"><i class="ri-search-line"></i></li></a>
        <li class="menu-li animate__animated  animate__fadeInUp lang-switcher-desktop">
          <a href="/2026/02/15/Convolutional-Neural-Network/index.html">EN</a> |
          <a href="/2026/02/15/Convolutional-Neural-Network/index-zh.html">中文</a>
        </li>
        <li class="menu-li animate__animated  animate__fadeInUp" id="mobile-menu"><i class="ri-menu-line"></i></li>
      </ul>
    </div>
  </div>
</div>

<div id="mobile-main" class="animate__animated  animate__fadeIn">
  <div class="mobile-menu-inner">
    <div class="mobile-menu-site-name animate__animated  animate__fadeInUp"><a href="/">Rongyan&#39;s Blog</a></div>
    <div class="mobile-menu-group" id="mobile-close"><i class="ri-close-line"></i></div>
  </div>
  <div class="mobile-menu-div">
    <a href="/" class="mobile-nav-link"><div class="mobile-menu-child animate__animated  animate__fadeInUp"><span>HOME</span></div></a>
    <a href="/archives" class="mobile-nav-link"><div class="mobile-menu-child animate__animated  animate__fadeInUp"><span>BLOG</span></div></a>
    <div class="mobile-menu-child animate__animated  animate__fadeInUp lang-switcher-mobile">
      <a href="/2026/02/15/Convolutional-Neural-Network/index.html">EN</a> |
      <a href="/2026/02/15/Convolutional-Neural-Network/index-zh.html">中文</a>
    </div>
    <a href="/search"><div class="mobile-menu-child  animate__animated  animate__fadeInUp"><i class="ri-search-line"></i></div></a>
  </div>
</div>

<div class="body-outer">
  <div class="body-inner">
    <article class="post-inner">
      <div class="post-content-outer">
        <div class="post-intro">
          <div class="post-title animate__animated  animate__fadeInUp">02. Convolutional Neural Networks</div>
          <div class="meta-intro animate__animated  animate__fadeInUp">Feb 15 2026</div>
        </div>
        <div class="post-content-inner">
          <div class="post-content-inner-space"></div>
          <div class="post-content-main animate__animated  animate__fadeInUp">
            <h1 id="CNN"><a href="#CNN" class="headerlink" title="02. Convolutional Neural Networks"></a>02. Convolutional Neural Networks</h1>

            <h2 id="Conv"><a href="#Conv" class="headerlink" title="Convolutional Layer"></a>Section 1 Convolutional Layer</h2>
            <p><img src="/images/cnn/1764760108217.png" alt="Conv layer" class="post-img"></p>

            <h3>1. Basic concepts</h3>
            <ul>
              <li><strong>CONV layer</strong>: computes outputs for neurons connected to local receptive fields.</li>
              <li><strong>Local receptive field (LRF)</strong>: the region of the input a neuron “sees.”</li>
              <li><strong>Filter/Kernel</strong>: a weight matrix used to extract features.</li>
            </ul>

            <h3>2. How it works</h3>
            <ul>
              <li>Scan left‑to‑right, top‑to‑bottom.</li>
              <li>Output: \( w^T x + b \)</li>
              <li>Formula: \( \sum_{ij} x_{ij} w_{ij} + b \)</li>
            </ul>

            <h3>3. Parameter sharing</h3>
            <ul>
              <li>All LRFs share the same weights \(w\) and bias \(b\).</li>
            </ul>

            <h3>4. Output</h3>
            <ul>
              <li>Outputs form a <strong>feature map</strong> indicating extracted patterns.</li>
            </ul>

            <h3>Core CNN concepts</h3>
            <h4>Receptive field</h4>
            <ul>
              <li>Region of the input affecting one feature‑map pixel.</li>
              <li>Deeper layers → larger receptive field.</li>
            </ul>
            <h4>Stride</h4>
            <ul>
              <li>Step size of the kernel.</li>
              <li>Stride 1 keeps more detail; larger stride downsamples.</li>
            </ul>
            <h4>Padding</h4>
            <ul>
              <li>Adds pixels around borders.</li>
              <li>Valid: no padding; Same: preserve size.</li>
            </ul>

            <h2 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>1.2 Padding</h2>
            <p><img src="/images/cnn/1764760275582.png" alt="Padding" class="post-img"></p>
            <h3>Why padding?</h3>
            <ul>
              <li>Prevents feature maps from shrinking too quickly.</li>
              <li>Allows deeper networks.</li>
            </ul>
            <h3>Common types</h3>
            <ul>
              <li><strong>Valid</strong>: no padding, size shrinks.</li>
              <li><strong>Same</strong>: choose P to keep size.</li>
              <li><strong>Full</strong>: choose P so each pixel is covered by k LRFs.</li>
            </ul>
            <p><img src="/images/cnn/1764760839784.png" alt="Padding types" class="post-img"></p>

            <h2 id="Convolutions"><a href="#Convolutions" class="headerlink" title="Convolutions"></a>1.3 Convolutions</h2>
            <p><img src="/images/cnn/1764762064230.png" alt="Convolutions" class="post-img"></p>
            <h3>Translation invariance</h3>
            <ul>
              <li>Same filter detects the same pattern anywhere.</li>
              <li>Fewer samples needed to learn useful features.</li>
            </ul>
            <h3>Hierarchical patterns</h3>
            <ul>
              <li>Low‑level: edges, corners.</li>
              <li>Mid‑level: combinations of parts.</li>
              <li>High‑level: semantic parts (wheels, windows).</li>
            </ul>
            <h3>Parameter efficiency</h3>
            <ul>
              <li>Weight sharing + local connectivity reduce parameters.</li>
            </ul>
            <p><img src="/images/cnn/1764762041967.png" alt="ReLU" class="post-img"></p>
            <h3>Why ReLU in CNNs?</h3>
            <ul>
              <li>Simple and fast: \( f(x)=\max(0,x) \)</li>
              <li>Mitigates vanishing gradients.</li>
              <li>Enhances contrast by zeroing negatives.</li>
            </ul>

            <h2 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Section 2 Pooling Layer</h2>
            <p><img src="/images/cnn/1764762478648.png" alt="Pooling" class="post-img"></p>
            <h3>Why pooling?</h3>
            <ul>
              <li>Reduces resolution → fewer parameters and computation.</li>
              <li>Typical: 2×2, stride 2 → 1/4 elements.</li>
              <li>Improves translation invariance.</li>
            </ul>

            <h2 id="Dense"><a href="#Dense" class="headerlink" title="Dense Layer"></a>Section 3 Dense Layer</h2>
            <p><img src="/images/cnn/1764762643696.png" alt="Dense" class="post-img"></p>
            <ul>
              <li>Located near the end for final prediction.</li>
              <li>Flatten converts W×H×D to 1D vector.</li>
              <li>Flatten loses spatial info but keeps key parts.</li>
            </ul>

            <h2 id="Computation"><a href="#Computation" class="headerlink" title="Computation"></a>Section 4 Computation</h2>
            <p><img src="/images/cnn/1764763303942.png" alt="Computation" class="post-img"></p>
            <p><img src="/images/cnn/1764763315460.png" alt="Computation 2" class="post-img"></p>
            <p><img src="/images/cnn/1764763329122.png" alt="Computation 3" class="post-img"></p>
            <p><img src="/images/cnn/1764763347496.png" alt="Computation 4" class="post-img"></p>
            <p><img src="/images/cnn/1764763358575.png" alt="Computation 5" class="post-img"></p>
            <p><img src="/images/cnn/1764763368371.png" alt="Computation 6" class="post-img"></p>
            <p><img src="/images/cnn/1764764670407.png" alt="Receptive field" class="post-img"></p>
            <p>r is receptive field size, k is kernel (or pooling window) size, and j is the jump between adjacent output centers mapped to the input.</p>

            <h2 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualizing CNNs"></a>Section 5 Visualizing and Understanding CNN</h2>
            <h3>5.1 Probability Heat Maps</h3>
            <p><img src="/images/cnn/1764766071769.png" alt="Heat map" class="post-img"></p>
            <ul>
              <li>Use occlusion to see which regions matter most.</li>
              <li>Darker means bigger probability drop → more important.</li>
            </ul>

            <h3>5.2 Gradient Ascent Visualization</h3>
            <p><img src="/images/cnn/1764766256788.png" alt="Gradient ascent" class="post-img"></p>
            <ul>
              <li>Optimize input image to maximize a class score.</li>
              <li>\( \arg\max_I S_c(I) - \lambda \lVert I \rVert_2^2 \)</li>
              <li>Update: \( I \leftarrow I + \eta \cdot \nabla_I S_c(I) \)</li>
            </ul>

            <h3>5.3 Maximally Activating Patches</h3>
            <p><img src="/images/cnn/1764766427688.png" alt="Max patches" class="post-img"></p>
            <ul>
              <li>Collect top‑k patches that activate a neuron the most.</li>
              <li>Higher layers prefer more semantic patterns.</li>
            </ul>
            <p><img src="/images/cnn/1764767688054.png" alt="Patches 1" class="post-img"></p>
            <h3>5.4 Feature Space for Image Retrieval</h3>
            <ol>
              <li>
                <p><strong>Nearest neighbors in pixel space often fail</strong></p>
                <p><strong>Method:</strong> treat each image as a large pixel vector and measure distance using Euclidean distance (or sum of squared differences).</p>
                <p><strong>Problem:</strong> pixel similarity ≠ semantic similarity.</p>
                <p>Images with similar colors, backgrounds, or textures can be close in pixel space but belong to completely different object classes.</p>
                <p>Example: the same background (e.g., blue sky, grass) can make different objects appear similar; small changes in pose or position can make pixel distance large even when the semantics are unchanged.</p>
              </li>
              <li>
                <p><strong>Nearest neighbors using the final-layer feature vector is more reasonable</strong></p>
                <p><strong>Method:</strong> map images to feature vectors (embeddings) using a CNN, then perform nearest-neighbor search in that feature space.</p>
                <p><strong>Advantages:</strong></p>
                <p>High-level CNN features are more robust to translation, scaling, cropping, and lighting changes.</p>
                <p>The feature space aligns better with semantic similarity rather than pixel similarity.</p>
                <p><strong>Example results:</strong></p>
                <p>Dog images with different poses, colors, and backgrounds are close in feature space.</p>
                <p>Semantic categories (e.g., pumpkins, warships, flowers) form their own clusters in feature space.</p>
              </li>
            </ol>
            <p><strong>Key takeaway:</strong> For image retrieval, nearest neighbors in pixel space are easily misled by appearance, while nearest neighbors in deep features (the last CNN layer) better capture semantic similarity and improve retrieval accuracy.</p>

            <div class="post-categoris-bottom">
              <div class="post-categoris-name">AI</div>
              <ul>
                <li class="me base">
                  <a href="/2026/02/15/Convolutional-Neural-Network/" class="post-categoris-bottom-link">02. Convolutional Neural Networks</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="post-content-inner-space">
            <div class="space-toc-main animate__animated  animate__fadeInUp">
              <ol class="space-toc">
                <li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Conv"><span class="space-toc-text">Section 1 Convolutional Layer</span></a></li>
                <li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Padding"><span class="space-toc-text">1.2 Padding</span></a></li>
                <li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Convolutions"><span class="space-toc-text">1.3 Convolutions</span></a></li>
                <li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Pooling"><span class="space-toc-text">Section 2 Pooling Layer</span></a></li>
                <li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Dense"><span class="space-toc-text">Section 3 Dense Layer</span></a></li>
                <li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Computation"><span class="space-toc-text">Section 4 Computation</span></a></li>
                <li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Visualization"><span class="space-toc-text">Section 5 Visualizing and Understanding CNN</span></a></li>
              </ol>
            </div>
          </div>
        </div>
      </div>
    </article>
  </div>
</div>

<div class="footer-outer animate__animated  animate__fadeInUp">
  <div class="footer-inner">
    <div class="footer-text">
      <p>Artificial Intelligence |  Financial Engineering | Mathematics | Computer Science  <strong>Rongyan <i class="ri-copyright-line"></i> 2026</strong></p>
    </div>
    <div class="footer-contact">
      <ul class="footer-ul">
        <li class="footer-li"><a href="https://github.com/RongyanYuan" target="_blank"><i class="ri-github-line"></i></a></li>
        <li class="footer-li"><a href="mailto:adrianrongyanyun@gmail.com" target="_blank"><i class="ri-mail-line"></i></a></li>
        <li class="footer-li"><a href="https://www.linkedin.com/in/rongyan-yuan-a076971b2/" target="_blank"><i class="ri-linkedin-box-line"></i></a></li>
      </ul>
    </div>
  </div>
</div>

<script src="/js/white.js"></script>
<script>
  window.MathJax = {
    tex: {inlineMath: [['\\(','\\)'], ['$', '$']]},
    svg: {fontCache: 'global'}
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</body>
</html>
