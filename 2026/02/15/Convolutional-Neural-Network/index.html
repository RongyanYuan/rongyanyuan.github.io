<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>  02. Convolutional Neural Networks |    Rongyan's Blog</title>
<meta content="Financial Engineering | Mathematics | Computer Science" name="description"/>
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet"/>
<link href="https://cdn.jsdelivr.net/gh/fushaolei/cdn-white@1.0/css/animate.css" rel="stylesheet">
<link href="/css/white.css" rel="stylesheet"/>
</link></head>
<body>
<div class="menu-outer">
<div class="menu-inner">
<div class="menu-site-name animate__animated animate__fadeInUp">
<a href="/">Rongyan's Blog</a>
<div class="menu-redirect"><a class="nav-link back-topic-link" href="/categories/ai/deep-learning/">← Deep Learning</a></div></div>
<div class="menu-group">
<ul class="menu-ul">
<a class="nav-link" href="/"><li class="menu-li animate__animated animate__fadeInUp">HOME</li></a>
<a class="nav-link" href="/archives"><li class="menu-li animate__animated animate__fadeInUp">BLOG</li></a>
<li class="menu-li animate__animated animate__fadeInUp" id="sort">
           CATEGORIES
           <div class="categories-outer" id="sort-div">
<ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AboutMe/">AboutMe</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ai/">AI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs/">CS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/quant/">Quant</a></li></ul>
</div>
</li>
<a href="/search"><li class="menu-li animate__animated animate__fadeInUp"><i class="ri-search-line"></i></li></a>
<li class="menu-li animate__animated animate__fadeInUp lang-switcher-desktop">
<a href="/2026/02/15/Convolutional-Neural-Network/index.html">EN</a> |
          <a href="/2026/02/15/Convolutional-Neural-Network/index-zh.html">中文</a>
</li>
<li class="menu-li animate__animated animate__fadeInUp" id="mobile-menu"><i class="ri-menu-line"></i></li>
</ul>
</div>
</div>
</div>
<div class="animate__animated animate__fadeIn" id="mobile-main">
<div class="mobile-menu-inner">
<div class="mobile-menu-site-name animate__animated animate__fadeInUp"><a href="/">Rongyan's Blog</a></div>
<div class="mobile-menu-group" id="mobile-close"><i class="ri-close-line"></i></div>
</div>
<div class="mobile-menu-div">
<a class="mobile-nav-link" href="/"><div class="mobile-menu-child animate__animated animate__fadeInUp"><span>HOME</span></div></a>
<a class="mobile-nav-link" href="/archives"><div class="mobile-menu-child animate__animated animate__fadeInUp"><span>BLOG</span></div></a>
<div class="mobile-menu-child animate__animated animate__fadeInUp lang-switcher-mobile">
<a href="/2026/02/15/Convolutional-Neural-Network/index.html">EN</a> |
      <a href="/2026/02/15/Convolutional-Neural-Network/index-zh.html">中文</a>
</div>
<a href="/search"><div class="mobile-menu-child animate__animated animate__fadeInUp"><i class="ri-search-line"></i></div></a>
</div>
</div>
<div class="body-outer">
<div class="body-inner">
<article class="post-inner">
<div class="post-content-outer">
<div class="post-intro">
<div class="post-title animate__animated animate__fadeInUp">02. Convolutional Neural Networks</div>
<div class="meta-intro animate__animated animate__fadeInUp">Feb 15 2026</div>
</div>
<div class="post-content-inner">
<div class="post-content-inner-space"></div>
<div class="post-content-main animate__animated animate__fadeInUp">
<h1 id="CNN"><a class="headerlink" href="#CNN" title="02. Convolutional Neural Networks"></a>02. Convolutional Neural Networks</h1>
<h2 id="Conv"><a class="headerlink" href="#Conv" title="Convolutional Layer"></a>Section 1 Convolutional Layer</h2>
<p><img alt="Conv layer" class="post-img" src="/images/cnn/1764760108217.png"/></p>
<h3>1. Basic concepts</h3>
<ul>
<li><strong>CONV layer</strong>: computes outputs for neurons connected to local receptive fields.</li>
<li><strong>Local receptive field (LRF)</strong>: the region of the input a neuron “sees.”</li>
<li><strong>Filter/Kernel</strong>: a weight matrix used to extract features.</li>
</ul>
<h3>2. How it works</h3>
<ul>
<li>Scan left‑to‑right, top‑to‑bottom.</li>
<li>Output: \( w^T x + b \)</li>
<li>Formula: \( \sum_{ij} x_{ij} w_{ij} + b \)</li>
</ul>
<h3>3. Parameter sharing</h3>
<ul>
<li>All LRFs share the same weights \(w\) and bias \(b\).</li>
</ul>
<h3>4. Output</h3>
<ul>
<li>Outputs form a <strong>feature map</strong> indicating extracted patterns.</li>
</ul>
<h3>Core CNN concepts</h3>
<h4>Receptive field</h4>
<ul>
<li>Region of the input affecting one feature‑map pixel.</li>
<li>Deeper layers → larger receptive field.</li>
</ul>
<h4>Stride</h4>
<ul>
<li>Step size of the kernel.</li>
<li>Stride 1 keeps more detail; larger stride downsamples.</li>
</ul>
<h4>Padding</h4>
<ul>
<li>Adds pixels around borders.</li>
<li>Valid: no padding; Same: preserve size.</li>
</ul>
<h2 id="Padding"><a class="headerlink" href="#Padding" title="Padding"></a>1.2 Padding</h2>
<p><img alt="Padding" class="post-img" src="/images/cnn/1764760275582.png"/></p>
<h3>Why padding?</h3>
<ul>
<li>Prevents feature maps from shrinking too quickly.</li>
<li>Allows deeper networks.</li>
</ul>
<h3>Common types</h3>
<ul>
<li><strong>Valid</strong>: no padding, size shrinks.</li>
<li><strong>Same</strong>: choose P to keep size.</li>
<li><strong>Full</strong>: choose P so each pixel is covered by k LRFs.</li>
</ul>
<p><img alt="Padding types" class="post-img" src="/images/cnn/1764760839784.png"/></p>
<h2 id="Convolutions"><a class="headerlink" href="#Convolutions" title="Convolutions"></a>1.3 Convolutions</h2>
<p><img alt="Convolutions" class="post-img" src="/images/cnn/1764762064230.png"/></p>
<h3>Translation invariance</h3>
<ul>
<li>Same filter detects the same pattern anywhere.</li>
<li>Fewer samples needed to learn useful features.</li>
</ul>
<h3>Hierarchical patterns</h3>
<ul>
<li>Low‑level: edges, corners.</li>
<li>Mid‑level: combinations of parts.</li>
<li>High‑level: semantic parts (wheels, windows).</li>
</ul>
<h3>Parameter efficiency</h3>
<ul>
<li>Weight sharing + local connectivity reduce parameters.</li>
</ul>
<p><img alt="ReLU" class="post-img" src="/images/cnn/1764762041967.png"/></p>
<h3>Why ReLU in CNNs?</h3>
<ul>
<li>Simple and fast: \( f(x)=\max(0,x) \)</li>
<li>Mitigates vanishing gradients.</li>
<li>Enhances contrast by zeroing negatives.</li>
</ul>
<h2 id="Pooling"><a class="headerlink" href="#Pooling" title="Pooling"></a>Section 2 Pooling Layer</h2>
<p><img alt="Pooling" class="post-img" src="/images/cnn/1764762478648.png"/></p>
<h3>Why pooling?</h3>
<ul>
<li>Reduces resolution → fewer parameters and computation.</li>
<li>Typical: 2×2, stride 2 → 1/4 elements.</li>
<li>Improves translation invariance.</li>
</ul>
<h2 id="Dense"><a class="headerlink" href="#Dense" title="Dense Layer"></a>Section 3 Dense Layer</h2>
<p><img alt="Dense" class="post-img" src="/images/cnn/1764762643696.png"/></p>
<ul>
<li>Located near the end for final prediction.</li>
<li>Flatten converts W×H×D to 1D vector.</li>
<li>Flatten loses spatial info but keeps key parts.</li>
</ul>
<h2 id="Computation"><a class="headerlink" href="#Computation" title="Computation"></a>Section 4 Computation</h2>
<p><img alt="Computation" class="post-img" src="/images/cnn/1764763303942.png"/></p>
<p><img alt="Computation 2" class="post-img" src="/images/cnn/1764763315460.png"/></p>
<p><img alt="Computation 3" class="post-img" src="/images/cnn/1764763329122.png"/></p>
<p><img alt="Computation 4" class="post-img" src="/images/cnn/1764763347496.png"/></p>
<p><img alt="Computation 5" class="post-img" src="/images/cnn/1764763358575.png"/></p>
<p><img alt="Computation 6" class="post-img" src="/images/cnn/1764763368371.png"/></p>
<p><img alt="Receptive field" class="post-img" src="/images/cnn/1764764670407.png"/></p>
<p>r is receptive field size, k is kernel (or pooling window) size, and j is the jump between adjacent output centers mapped to the input.</p>
<h2 id="Visualization"><a class="headerlink" href="#Visualization" title="Visualizing CNNs"></a>Section 5 Visualizing and Understanding CNN</h2>
<h3>5.1 Probability Heat Maps</h3>
<p><img alt="Heat map" class="post-img" src="/images/cnn/1764766071769.png"/></p>
<ul>
<li>Use occlusion to see which regions matter most.</li>
<li>Darker means bigger probability drop → more important.</li>
</ul>
<h3>5.2 Gradient Ascent Visualization</h3>
<p><img alt="Gradient ascent" class="post-img" src="/images/cnn/1764766256788.png"/></p>
<ul>
<li>Optimize input image to maximize a class score.</li>
<li>\( \arg\max_I S_c(I) - \lambda \lVert I \rVert_2^2 \)</li>
<li>Update: \( I \leftarrow I + \eta \cdot \nabla_I S_c(I) \)</li>
</ul>
<h3>5.3 Maximally Activating Patches</h3>
<p><img alt="Max patches" class="post-img" src="/images/cnn/1764766427688.png"/></p>
<ul>
<li>Collect top‑k patches that activate a neuron the most.</li>
<li>Higher layers prefer more semantic patterns.</li>
</ul>
<p><img alt="Patches 1" class="post-img" src="/images/cnn/1764767688054.png"/></p>
<h3>5.4 Feature Space for Image Retrieval</h3>
<ol>
<li>
<p><strong>Nearest neighbors in pixel space often fail</strong></p>
<p><strong>Method:</strong> treat each image as a large pixel vector and measure distance using Euclidean distance (or sum of squared differences).</p>
<p><strong>Problem:</strong> pixel similarity ≠ semantic similarity.</p>
<p>Images with similar colors, backgrounds, or textures can be close in pixel space but belong to completely different object classes.</p>
<p>Example: the same background (e.g., blue sky, grass) can make different objects appear similar; small changes in pose or position can make pixel distance large even when the semantics are unchanged.</p>
</li>
<li>
<p><strong>Nearest neighbors using the final-layer feature vector is more reasonable</strong></p>
<p><strong>Method:</strong> map images to feature vectors (embeddings) using a CNN, then perform nearest-neighbor search in that feature space.</p>
<p><strong>Advantages:</strong></p>
<p>High-level CNN features are more robust to translation, scaling, cropping, and lighting changes.</p>
<p>The feature space aligns better with semantic similarity rather than pixel similarity.</p>
<p><strong>Example results:</strong></p>
<p>Dog images with different poses, colors, and backgrounds are close in feature space.</p>
<p>Semantic categories (e.g., pumpkins, warships, flowers) form their own clusters in feature space.</p>
</li>
</ol>
<p><strong>Key takeaway:</strong> For image retrieval, nearest neighbors in pixel space are easily misled by appearance, while nearest neighbors in deep features (the last CNN layer) better capture semantic similarity and improve retrieval accuracy.</p>
<div class="post-categoris-bottom">
<div class="post-categoris-name">AI</div>
<ul>
<li class="me base">
<a class="post-categoris-bottom-link" href="/2026/02/16/CNN-Training-Pipeline/">03. CNN Training Task Pipeline</a>
</li>
</ul>
</div>
</div>
<div class="post-content-inner-space">
<div class="space-toc-main animate__animated animate__fadeInUp">
<ol class="space-toc">
<li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Conv"><span class="space-toc-text">Section 1 Convolutional Layer</span></a></li>
<li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Padding"><span class="space-toc-text">1.2 Padding</span></a></li>
<li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Convolutions"><span class="space-toc-text">1.3 Convolutions</span></a></li>
<li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Pooling"><span class="space-toc-text">Section 2 Pooling Layer</span></a></li>
<li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Dense"><span class="space-toc-text">Section 3 Dense Layer</span></a></li>
<li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Computation"><span class="space-toc-text">Section 4 Computation</span></a></li>
<li class="space-toc-item space-toc-level-2"><a class="space-toc-link" href="#Visualization"><span class="space-toc-text">Section 5 Visualizing and Understanding CNN</span></a></li>
</ol>
</div>
</div>
</div>
</div>
</article>
</div>
</div>
<div class="footer-outer animate__animated animate__fadeInUp">
<div class="footer-inner">
<div class="footer-text">
<p>Artificial Intelligence |  Financial Engineering | Mathematics | Computer Science  <strong>Rongyan <i class="ri-copyright-line"></i> 2026</strong></p>
</div>
<div class="footer-contact">
<ul class="footer-ul">
<li class="footer-li"><a href="https://github.com/RongyanYuan" target="_blank"><i class="ri-github-line"></i></a></li>
<li class="footer-li"><a href="mailto:adrianrongyanyun@gmail.com" target="_blank"><i class="ri-mail-line"></i></a></li>
<li class="footer-li"><a href="https://www.linkedin.com/in/rongyan-yuan-a076971b2/" target="_blank"><i class="ri-linkedin-box-line"></i></a></li>
</ul>
</div>
</div>
</div>
<script src="/js/white.js"></script>
<script>
  window.MathJax = {
    tex: {inlineMath: [['\\(','\\)'], ['$', '$']]},
    svg: {fontCache: 'global'}
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</body>
</html>
